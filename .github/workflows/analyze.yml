
name: Generate Report

on:
  issues:
    types: [opened]

# نسمح للـ workflow يرفع artifacts ويكتب تعليق على الـ Issues
permissions:
  contents: write
  issues: write

jobs:
  analyze:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install Chrome
        uses: browser-actions/setup-chrome@v1

      # هنستخدم فقط الحزم الضرورية: Lighthouse + Cheerio
      - name: Install dependencies
        run: |
          npm init -y
          npm install @lhci/cli@0.13.x cheerio

      # نستخرج الرابط من عنوان/متن الـ Issue ونخزّنه كـ URL
      - name: Extract URL from issue (title/body)
        id: extract
        run: |
          TITLE=$(jq -r '.issue.title' "$GITHUB_EVENT_PATH")
          BODY=$(jq -r '.issue.body' "$GITHUB_EVENT_PATH")
          URL=$(echo "$TITLE" | grep -oE 'https?://[^ ]+' || true)
          if [ -z "$URL" ]; then
            URL=$(echo "$BODY" | grep -oE 'https?://[^ ]+' | head -n1 || true)
          fi
          if [ -z "$URL" ]; then
            echo "❌ لم يتم العثور على URL داخل الـ Issue."
            exit 1
          fi
          echo "URL=$URL" >> $GITHUB_ENV
          echo "✅ Using URL: $URL"

      - name: Create output folder
        run: mkdir -p reports/$GITHUB_RUN_ID

      - name: Run Lighthouse
        env:
          URL: ${{ env.URL }}
        run: |
          echo "Running Lighthouse for $URL"
          npx @lhci/cli collect \
            --url "$URL" \
            --numberOfRuns=1 \
            --outputDir="reports/$GITHUB_RUN_ID/lh" \
            --report=html,json \
            --settings.chromePath="$(which chrome)" \
            --settings.chromeFlags="--headless=new --no-sandbox --disable-gpu"

      - name: Scrape SEO elements (ESM)
        env:
          URL: ${{ env.URL }}
        run: |
          node --input-type=module << 'EOF'
          import { writeFileSync } from 'fs';
          import { load } from 'cheerio';

          const url = process.env.URL;
          const res = await fetch(url, { headers: { 'User-Agent': 'SEO-Auditor/1.0' }});
          const html = await res.text();
          const $ = load(html);

          const data = {
            url,
            title: $('title').text()?.trim() || '',
            metaDesc: $('meta[name="description"]').attr('content') || '',
            h1: $('h1').first().text()?.trim() || '',
            canonical: $('link[rel="canonical"]').attr('href') || '',
            robots: $('meta[name="robots"]').attr('content') || ''
          };

          writeFileSync(`reports/${process.env.GITHUB_RUN_ID}/seo.json`, JSON.stringify(data, null, 2));
          EOF

      - name: Check broken links (custom ESM)
        env:
          URL: ${{ env.URL }}
        run: |
          node --input-type=module << 'EOF'
          import { load } from 'cheerio';
          import { writeFileSync } from 'fs';

          const baseUrl = process.env.URL;

          // جلب HTML وجمع الروابط
          const page = await fetch(baseUrl, { headers: { 'User-Agent': 'SEO-Auditor/1.0' }});
          const html = await page.text();
          const $ = load(html);

          // تحويل أي رابط نسبي إلى مطلق
          const toAbs = (base, href) => {
            try { return new URL(href, base).href; } catch { return null; }
          };

          const hrefs = new Set();
          $('a[href]').each((_, el) => {
            const abs = toAbs(baseUrl, $(el).attr('href'));
            if (abs) hrefs.add(abs);
          });

          // نحط حد أقصى للروابط عشان زمن الجوب (مثلاً 150)
          const MAX = 150;
          const urls = Array.from(hrefs).slice(0, MAX);

          // وظيفة طلب مع مهلة
          const check = async (u) => {
            const controller = new AbortController();
            const id = setTimeout(() => controller.abort(), 12000); // 12s timeout
            try {
              // جرّب HEAD أولاً؛ لو فشل استخدم GET خفيف
              let r = await fetch(u, { method: 'HEAD', redirect: 'follow', signal: controller.signal });
              if (!r.ok || r.status >= 400) {
                r = await fetch(u, { method: 'GET', redirect: 'follow', signal: controller.signal });
              }
              clearTimeout(id);
              return { url: u, status: r.status, ok: r.ok };
            } catch (e) {
              clearTimeout(id);
              return { url: u, status: 0, ok: false, error: String(e?.name || e) };
            }
          };

          const results = [];
          // نعمل دفعات صغيرة لتقليل الضغط
          const BATCH = 15;
          for (let i=0; i<urls.length; i+=BATCH) {
            const chunk = urls.slice(i, i+BATCH);
            const out = await Promise.all(chunk.map(check));
            results.push(...out);
          }

          const broken = results.filter(x => !x.ok || x.status >= 400)
                                .map(x => ({ url: x.url, status: x.status || 'ERR', error: x.error || '' }));

          writeFileSync(`reports/${process.env.GITHUB_RUN_ID}/links.json`, JSON.stringify({
            scanned: urls.length,
            brokenCount: broken.length,
            broken
          }, null, 2));
          EOF

      - name: Upload report as artifact
        uses: actions/upload-artifact@v4
        with:
          name: report-${{ github.run_id }}
          path: reports/${{ github.run_id }}

      - name: Comment back with link (REST)
        env:
          RUN_ID: ${{ github.run_id }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO: ${{ github.repository }}
          ISSUE_NUMBER: ${{ github.event.issue.number }}
        run: |
          API="https://api.github.com/repos/$REPO/issues/$ISSUE_NUMBER/comments"
          BODY=$(cat <<EOF
          { "body": "✅ Report ready! Download artifacts:\nhttps://github.com/$REPO/actions/runs/$RUN_ID" }
          EOF
          )
          curl -s -f -X POST "$API" \
            -H "Authorization: Bearer $GITHUB_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            -d "$BODY"
